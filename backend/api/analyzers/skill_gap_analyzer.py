"""
Skill Gap Analyzer â€” B2
ë‚´ê°€ ì‚¬ìš©í•˜ëŠ” ì„ ìˆ˜ë¡œ ë­ì»¤ê°€ ë™ì¼ ì„ ìˆ˜ë¡œ ë‚´ëŠ” ì„±ì ê³¼ ë‚´ ì„±ì ì„ ë¹„êµ,
êµ¬ì²´ì ì¸ ì‹¤ë ¥ ê²©ì°¨ë¥¼ Z-scoreë¡œ ìˆ˜ì¹˜í™”.
"""
import math
from typing import List, Dict, Any


class SkillGapAnalyzer:
    """ë­ì»¤ ëŒ€ë¹„ ë‚´ ì„ ìˆ˜ í™œìš© ê²©ì°¨ ë¶„ì„ê¸°"""

    METRICS_CONFIG = {
        'avg_rating': {
            'label': 'í‰ê·  í‰ì ',
            'description': 'spRating ê¸°ì¤€ ê²½ê¸° í‰ì  (0~10)',
            'higher_better': True,
            'weight': 2.5,
        },
        'goals_per_game': {
            'label': 'ê²½ê¸°ë‹¹ ë“ì ',
            'description': 'ê²½ê¸°ë‹¹ í‰ê·  ê³¨ ìˆ˜',
            'higher_better': True,
            'weight': 2.0,
        },
        'assists_per_game': {
            'label': 'ê²½ê¸°ë‹¹ ì–´ì‹œìŠ¤íŠ¸',
            'description': 'ê²½ê¸°ë‹¹ í‰ê·  ì–´ì‹œìŠ¤íŠ¸ ìˆ˜',
            'higher_better': True,
            'weight': 1.5,
        },
        'shot_accuracy': {
            'label': 'ìŠˆíŒ… ì •í™•ë„',
            'description': 'ìœ íš¨ìŠ› / ì´ ìŠ› ë¹„ìœ¨ (%)',
            'higher_better': True,
            'weight': 1.5,
        },
        'pass_accuracy': {
            'label': 'íŒ¨ìŠ¤ ì„±ê³µë¥ ',
            'description': 'íŒ¨ìŠ¤ ì„±ê³µ / íŒ¨ìŠ¤ ì‹œë„ ë¹„ìœ¨ (%)',
            'higher_better': True,
            'weight': 1.0,
        },
        'dribble_success_rate': {
            'label': 'ë“œë¦¬ë¸” ì„±ê³µë¥ ',
            'description': 'ë“œë¦¬ë¸” ì„±ê³µ / ë“œë¦¬ë¸” ì‹œë„ ë¹„ìœ¨ (%)',
            'higher_better': True,
            'weight': 1.0,
        },
    }

    GAP_LEVEL_LABELS = {
        'ranker_level': {'label': 'ë­ì»¤ê¸‰', 'color': 'gold', 'emoji': 'ğŸ†'},
        'near_ranker': {'label': 'ë­ì»¤ ê·¼ì ‘', 'color': 'green', 'emoji': 'âœ…'},
        'slight_gap': {'label': 'ì†Œí­ ê²©ì°¨', 'color': 'yellow', 'emoji': 'ğŸ“ˆ'},
        'moderate_gap': {'label': 'ì¤‘ê°„ ê²©ì°¨', 'color': 'orange', 'emoji': 'âš ï¸'},
        'significant_gap': {'label': 'í° ê²©ì°¨', 'color': 'red', 'emoji': 'ğŸ”´'},
        'large_gap': {'label': 'ë§¤ìš° í° ê²©ì°¨', 'color': 'darkred', 'emoji': 'ğŸš¨'},
    }

    @staticmethod
    def _extract_my_stats(performances: List[Dict]) -> Dict[str, float]:
        """PlayerPerformance ë¦¬ìŠ¤íŠ¸ì—ì„œ í‰ê·  í†µê³„ ì¶”ì¶œ"""
        if not performances:
            return {}

        total = len(performances)
        total_rating = sum(float(p.get('rating', 0)) for p in performances)
        total_goals = sum(int(p.get('goals', 0)) for p in performances)
        total_assists = sum(int(p.get('assists', 0)) for p in performances)
        total_shots = sum(int(p.get('shots', 0)) for p in performances)
        total_shots_on = sum(int(p.get('shots_on_target', 0)) for p in performances)
        total_pass_try = sum(int(p.get('pass_attempts', 0)) for p in performances)
        total_pass_success = sum(int(p.get('pass_success', 0)) for p in performances)
        total_dribble_try = sum(int(p.get('dribble_attempts', 0)) for p in performances)
        total_dribble_success = sum(int(p.get('dribble_success', 0)) for p in performances)

        return {
            'avg_rating': total_rating / total,
            'goals_per_game': total_goals / total,
            'assists_per_game': total_assists / total,
            'shot_accuracy': (total_shots_on / total_shots * 100) if total_shots > 0 else 0,
            'pass_accuracy': (total_pass_success / total_pass_try * 100) if total_pass_try > 0 else 0,
            'dribble_success_rate': (total_dribble_success / total_dribble_try * 100) if total_dribble_try > 0 else 0,
        }

    # Estimated std values for each metric (used when API returns pre-aggregated avg only)
    METRIC_STDS = {
        'avg_rating': 0.6,
        'goals_per_game': 0.35,
        'assists_per_game': 0.25,
        'shot_accuracy': 18.0,
        'pass_accuracy': 10.0,
        'dribble_success_rate': 15.0,
    }

    # Ranker avg rating (spRating not in ranker-stats API, use domain estimate)
    RANKER_AVG_RATING = 7.2

    @classmethod
    def _extract_ranker_stats(cls, ranker_status_list: List[Dict]) -> Dict[str, Dict[str, float]]:
        """
        ë­ì»¤ statusì—ì„œ ê° ë©”íŠ¸ë¦­ì˜ í‰ê·  ì¶”ì¶œ.
        Nexon API ranker-statsëŠ” ì„ ìˆ˜ë³„ ë­ì»¤ í‰ê· ì„ pre-aggregated dict í•˜ë‚˜ë¡œ ë°˜í™˜í•¨.
        """
        if not ranker_status_list:
            return {}

        metrics: Dict[str, List[float]] = {
            'avg_rating': [],
            'goals_per_game': [],
            'assists_per_game': [],
            'shot_accuracy': [],
            'pass_accuracy': [],
            'dribble_success_rate': [],
        }

        for s in ranker_status_list:
            # spRatingì€ ranker-stats APIì— ì—†ìœ¼ë¯€ë¡œ ë„ë©”ì¸ ì¶”ì •ê°’ ì‚¬ìš©
            # (ê°œë³„ stat dictì— ìˆë‹¤ë©´ ê·¸ê±¸ ì“°ê³ , ì—†ìœ¼ë©´ ìƒìˆ˜)
            rating = float(s.get('spRating', cls.RANKER_AVG_RATING))
            metrics['avg_rating'].append(rating)

            # Goals / Assists (API í•„ë“œ: goal, assist)
            metrics['goals_per_game'].append(float(s.get('goal', 0)))
            metrics['assists_per_game'].append(float(s.get('assist', 0)))

            # Shot accuracy: effectiveShoot / shoot (%)
            shots = float(s.get('shoot', 0))
            shots_on = float(s.get('effectiveShoot', 0))
            metrics['shot_accuracy'].append((shots_on / shots * 100) if shots > 0 else 0)

            # Pass accuracy: passSuccess / passTry (%)
            pass_try = float(s.get('passTry', 0))
            pass_success = float(s.get('passSuccess', 0))
            metrics['pass_accuracy'].append((pass_success / pass_try * 100) if pass_try > 0 else 0)

            # Dribble success rate: dribbleSuccess / dribbleTry (%)
            dribble_try = float(s.get('dribbleTry', 0))
            dribble_success = float(s.get('dribbleSuccess', 0))
            metrics['dribble_success_rate'].append(
                (dribble_success / dribble_try * 100) if dribble_try > 0 else 0
            )

        result = {}
        for metric, values in metrics.items():
            non_zero = [v for v in values if v > 0]
            if not non_zero:
                continue
            n = len(non_zero)
            avg = sum(non_zero) / n
            # APIê°€ pre-aggregated í‰ê· ë§Œ ì œê³µí•˜ë¯€ë¡œ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ std ì‚¬ìš©
            if n == 1:
                std = cls.METRIC_STDS.get(metric, 1.0)
            else:
                variance = sum((v - avg) ** 2 for v in non_zero) / n
                std = math.sqrt(variance) if variance > 0 else cls.METRIC_STDS.get(metric, 1.0)

            result[metric] = {'avg': round(avg, 3), 'std': round(std, 3), 'n': n}

        return result

    @staticmethod
    def _z_to_percentile(z: float) -> float:
        """Z-score â†’ ë°±ë¶„ìœ„ (0~100)"""
        from math import erf, sqrt
        z = max(-4.0, min(4.0, z))
        percentile = 50.0 * (1.0 + erf(z / sqrt(2.0)))
        return round(percentile, 1)

    @staticmethod
    def _gap_level(z: float) -> str:
        if z >= 1.0:
            return 'ranker_level'
        elif z >= 0.0:
            return 'near_ranker'
        elif z >= -0.5:
            return 'slight_gap'
        elif z >= -1.0:
            return 'moderate_gap'
        elif z >= -2.0:
            return 'significant_gap'
        else:
            return 'large_gap'

    @classmethod
    def analyze_player_gap(
        cls,
        spid: int,
        player_name: str,
        position: int,
        appearances: int,
        performances: List[Dict],
        ranker_status_list: List[Dict],
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì„ ìˆ˜ì— ëŒ€í•œ Skill Gap ë¶„ì„.

        Returns:
            {spid, player_name, appearances, metric_gaps, priority_improvements,
             overall_z_score, overall_level, ranker_proximity}
        """
        my_stats = cls._extract_my_stats(performances)
        ranker_stats = cls._extract_ranker_stats(ranker_status_list)

        if not my_stats or not ranker_stats:
            return {}

        gaps = {}
        priority_improvements = []

        for metric, config in cls.METRICS_CONFIG.items():
            if metric not in my_stats or metric not in ranker_stats:
                continue

            my_val = my_stats[metric]
            ranker_avg = ranker_stats[metric]['avg']
            ranker_std = ranker_stats[metric]['std']
            n_rankers = ranker_stats[metric].get('n', 0)

            z_score = (my_val - ranker_avg) / ranker_std if ranker_std > 0 else 0.0
            z_score = round(z_score, 2)

            gaps[metric] = {
                'label': config['label'],
                'description': config['description'],
                'my_value': round(my_val, 2),
                'ranker_avg': round(ranker_avg, 2),
                'ranker_std': round(ranker_std, 2),
                'n_rankers': n_rankers,
                'z_score': z_score,
                'percentile': cls._z_to_percentile(z_score),
                'gap_level': cls._gap_level(z_score),
                'gap_level_info': cls.GAP_LEVEL_LABELS.get(cls._gap_level(z_score), {}),
            }

            if z_score < -0.5:
                priority_improvements.append({
                    'metric': metric,
                    'label': config['label'],
                    'description': config['description'],
                    'gap': round(abs(z_score), 2),
                    'my_value': round(my_val, 2),
                    'ranker_avg': round(ranker_avg, 2),
                })

        priority_improvements.sort(key=lambda x: x['gap'], reverse=True)

        # Weighted overall Z-score
        total_weight = 0.0
        weighted_sum = 0.0
        for metric, config in cls.METRICS_CONFIG.items():
            if metric in gaps:
                weighted_sum += gaps[metric]['z_score'] * config['weight']
                total_weight += config['weight']

        overall_z = (weighted_sum / total_weight) if total_weight > 0 else 0.0

        # Generate Korean improvement guide
        guide = cls._generate_guide(gaps, player_name, priority_improvements)

        return {
            'spid': spid,
            'player_name': player_name,
            'position': position,
            'appearances': appearances,
            'metric_gaps': gaps,
            'priority_improvements': priority_improvements[:3],
            'overall_z_score': round(overall_z, 2),
            'overall_level': cls._gap_level(overall_z),
            'overall_level_info': cls.GAP_LEVEL_LABELS.get(cls._gap_level(overall_z), {}),
            'ranker_proximity': cls._z_to_percentile(overall_z),
            'improvement_guide': guide,
        }

    @staticmethod
    def _generate_guide(gaps: Dict, player_name: str, improvements: List[Dict]) -> List[str]:
        """ë­ì»¤ ìˆ˜ì¤€ ë‹¬ì„±ì„ ìœ„í•œ í•œêµ­ì–´ ê°€ì´ë“œ ìƒì„±"""
        guide = []
        if not improvements:
            guide.append(f"âœ… {player_name} í™œìš©ë„ê°€ ë­ì»¤ ìˆ˜ì¤€ì— ê·¼ì ‘í•©ë‹ˆë‹¤!")
            return guide

        top = improvements[0]
        metric = top['metric']
        my_val = top['my_value']
        ranker_avg = top['ranker_avg']

        if metric == 'avg_rating':
            guide.append(f"ğŸ¯ {player_name}ì˜ í‰ê·  í‰ì ì„ {my_val:.1f} â†’ {ranker_avg:.1f}ìœ¼ë¡œ ì˜¬ë¦¬ì„¸ìš”. "
                         f"ë” ì ê·¹ì ì¸ ìˆ˜ë¹„ ê°€ë‹´ê³¼ í‚¬íŒ¨ìŠ¤ê°€ í‰ì ì„ ë†’ì…ë‹ˆë‹¤.")
        elif metric == 'goals_per_game':
            guide.append(f"âš½ {player_name}ì˜ ê²½ê¸°ë‹¹ ë“ì ì„ {my_val:.2f} â†’ {ranker_avg:.2f}ìœ¼ë¡œ ëŠ˜ë¦¬ì„¸ìš”. "
                         f"íŒ¨ë„í‹°ë°•ìŠ¤ ì•ˆì—ì„œ ìŠˆíŒ… ê¸°íšŒë¥¼ ë” ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.")
        elif metric == 'assists_per_game':
            guide.append(f"ğŸ…°ï¸ {player_name}ì˜ ê²½ê¸°ë‹¹ ì–´ì‹œìŠ¤íŠ¸ë¥¼ {my_val:.2f} â†’ {ranker_avg:.2f}ìœ¼ë¡œ ëŠ˜ë¦¬ì„¸ìš”. "
                         f"ìŠ¤ë£¨íŒ¨ìŠ¤ í™œìš©ë„ë¥¼ ë†’ì´ê³  ë¹ˆ ê³µê°„ ì¹¨íˆ¬ë¥¼ ìœ ë„í•˜ì„¸ìš”.")
        elif metric == 'shot_accuracy':
            guide.append(f"ğŸ¯ {player_name}ì˜ ìŠˆíŒ… ì •í™•ë„ë¥¼ {my_val:.1f}% â†’ {ranker_avg:.1f}%ë¡œ ë†’ì´ì„¸ìš”. "
                         f"íŒ¨ë„í‹°ë°•ìŠ¤ ì•ˆì—ì„œì˜ ìœ íš¨ìŠˆíŒ… ë¹„ìœ¨ì„ ê°œì„ í•˜ì„¸ìš”.")
        elif metric == 'pass_accuracy':
            guide.append(f"â†—ï¸ {player_name}ì˜ íŒ¨ìŠ¤ ì„±ê³µë¥ ì„ {my_val:.1f}% â†’ {ranker_avg:.1f}%ë¡œ ë†’ì´ì„¸ìš”. "
                         f"ì••ë°• ìƒí™©ì—ì„œ ë¬´ë¦¬í•œ ì¥íŒ¨ìŠ¤ë³´ë‹¤ ì§§ì€ íŒ¨ìŠ¤ë¥¼ í™œìš©í•˜ì„¸ìš”.")
        elif metric == 'dribble_success_rate':
            guide.append(f"ğŸƒ {player_name}ì˜ ë“œë¦¬ë¸” ì„±ê³µë¥ ì„ {my_val:.1f}% â†’ {ranker_avg:.1f}%ë¡œ ë†’ì´ì„¸ìš”. "
                         f"ì¢ì€ ê³µê°„ì—ì„œì˜ ë“œë¦¬ë¸”ë³´ë‹¤ ë„“ì€ ê³µê°„ì„ í™œìš©í•˜ì„¸ìš”.")

        if len(improvements) > 1:
            second = improvements[1]
            guide.append(f"ë‹¤ìŒ ê°œì„  í¬ì¸íŠ¸: {second['label']} "
                         f"(í˜„ì¬ {second['my_value']:.1f} vs ë­ì»¤ {second['ranker_avg']:.1f})")

        return guide

    @classmethod
    def generate_overall_insights(cls, player_gaps: List[Dict]) -> List[str]:
        """ì „ì²´ ì„ ìˆ˜ ëª©ë¡ì— ëŒ€í•œ ì¢…í•© ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        if not player_gaps:
            return ['ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. 5ê²½ê¸° ì´ìƒ í”Œë ˆì´í•œ ì„ ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.']

        valid = [p for p in player_gaps if p.get('overall_z_score') is not None]
        if not valid:
            return ['ë­ì»¤ ìŠ¤íƒ¯ ë¹„êµ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.']

        valid.sort(key=lambda x: x['overall_z_score'], reverse=True)
        best = valid[0]
        worst = valid[-1]

        if best['overall_z_score'] >= 0:
            insights.append(
                f"ğŸ† {best['player_name']}ì´(ê°€) ê°€ì¥ ë­ì»¤ì— ê·¼ì ‘í•œ í™œìš©ë„ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤ "
                f"(ìƒìœ„ {100 - best['ranker_proximity']:.0f}% ìˆ˜ì¤€)"
            )

        if worst['overall_z_score'] < -1.0 and worst['priority_improvements']:
            top_improve = worst['priority_improvements'][0]
            insights.append(
                f"âš ï¸ {worst['player_name']}ì˜ {top_improve['label']} ê°œì„ ì´ ê°€ì¥ ì‹œê¸‰í•©ë‹ˆë‹¤ "
                f"(í˜„ì¬ {top_improve['my_value']:.1f} vs ë­ì»¤ {top_improve['ranker_avg']:.1f})"
            )

        near_ranker_count = sum(1 for p in valid if p['overall_z_score'] >= -0.5)
        insights.append(
            f"ğŸ“Š ë¶„ì„ ì„ ìˆ˜ {len(valid)}ëª… ì¤‘ {near_ranker_count}ëª…ì´ ë­ì»¤ ìˆ˜ì¤€ì˜ 80% ì´ìƒì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤."
        )

        # Trend check (if we have enough players)
        if len(valid) >= 3:
            avg_z = sum(p['overall_z_score'] for p in valid) / len(valid)
            if avg_z >= 0:
                insights.append("âœ… ì „ë°˜ì ìœ¼ë¡œ ë­ì»¤ì™€ ë¹„êµí•´ ì¤€ìˆ˜í•œ ì„ ìˆ˜ í™œìš©ë„ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤!")
            elif avg_z >= -1.0:
                insights.append("ğŸ“ˆ ì „ë°˜ì ì¸ ì„ ìˆ˜ í™œìš©ë„ê°€ ë­ì»¤ë³´ë‹¤ ì•½ê°„ ë‚®ìŠµë‹ˆë‹¤. ê°œì„  ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.")
            else:
                insights.append("ğŸ”´ ì „ë°˜ì ì¸ ì„ ìˆ˜ í™œìš©ë„ê°€ ë­ì»¤ë³´ë‹¤ ìƒë‹¹íˆ ë‚®ìŠµë‹ˆë‹¤. ì§‘ì¤‘ í›ˆë ¨ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        return insights
